{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea513e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "import time\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pylab \n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890eee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_read():\n",
    "    '''\n",
    "    This function is to read data from files. Since I only need top 1M, I take only df1\n",
    "    '''\n",
    "    df1 = pd.read_csv('data/combined_data_1.txt', header = None, names = ['Cust_Id', 'Rating',\"Date\"], usecols = [0,1,2])\n",
    "    #df2 = pd.read_csv('data/combined_data_2.txt', header = None, names = ['Cust_Id', 'Rating',\"Date\"], usecols = [0,1,2])\n",
    "    #df3 = pd.read_csv('data/combined_data_3.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n",
    "    #df4 = pd.read_csv('data/combined_data_4.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n",
    "\n",
    "    df1['Rating'] = df1['Rating'].astype(float)\n",
    "\n",
    "    print('Dataset 1 shape: {}'.format(df1.shape))\n",
    "    print('-Dataset examples-')\n",
    "    print(df1.iloc[::5000000, :])\n",
    "    \n",
    "    df = df1\n",
    "    #df = df.append(df2)\n",
    "    #df = df.append(df3)\n",
    "    #df = df.append(df4)\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0e0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_purify(df):\n",
    "    '''\n",
    "    Next section of codes is to extract the movie id for each of the data.\n",
    "    top 1M data is selected.\n",
    "    '''\n",
    "    start = time.time()\n",
    "    df = df.reset_index()\n",
    "    df_nan = pd.DataFrame(pd.isnull(df.Rating))\n",
    "    df_nan = df_nan[df_nan['Rating'] == True]\n",
    "    df_nan = df_nan.reset_index()\n",
    "    #print(df_nan[df_nan[\"index\"] == 0])\n",
    "    \n",
    "    movie_np = []\n",
    "    movie_id = 1\n",
    "\n",
    "    for i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n",
    "        # numpy approach\n",
    "        temp = np.full((i-j-1), movie_id)\n",
    "        movie_np = np.append(movie_np, temp)\n",
    "        movie_id += 1\n",
    "\n",
    "    # Account for last record and corresponding length\n",
    "    # numpy approach\n",
    "    last_record = np.full((1,len(df) - df_nan.iloc[-1, 0] - 1),movie_id)\n",
    "    movie_np = np.append(movie_np, last_record)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"time is \", end-start)\n",
    "    print('Movie numpy: {}'.format(movie_np))\n",
    "    print('Length: {}'.format(len(movie_np)))\n",
    "    \n",
    "    df = df[pd.notnull(df['Rating'])]\n",
    "    df['Movie_Id'] = movie_np.astype(int)\n",
    "    df['Cust_Id'] = df['Cust_Id'].astype(int)\n",
    "    print('-Dataset examples-')\n",
    "    print(df.iloc[::5000000, :])\n",
    "    df = df.iloc[:1000000, :]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a44bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_time(df):    \n",
    "    '''\n",
    "    Next section of code is to sort and group data by time\n",
    "    '''\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df.sort_values(by=['Date'])\n",
    "    group = df.groupby(df['Date'].map(lambda x:x.year))\n",
    "    for key, con in group:\n",
    "        print(key, con)\n",
    "    group_dic = [v for _,v in group]\n",
    "    return group_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2619b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing():\n",
    "    '''\n",
    "    \n",
    "    returns:\n",
    "        dict: group_dic. This is a dictionary which contains all top 1M data grouped by years\n",
    "    \n",
    "    This function is used to preprocess the data.\n",
    "    \n",
    "    '''\n",
    "    df = data_read()\n",
    "    df = data_purify(df)\n",
    "    group_dic = group_by_time(df)\n",
    "    \n",
    "    return group_dic   \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274dcce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The section of codes consists of 4 functions used in network projections.\n",
    "\n",
    "'''\n",
    "def df_to_edges(df):\n",
    "    temp_df = df[[\"Cust_Id\", \"Movie_Id\", \"Rating\"]]\n",
    "    temp_df[\"Cust_Id\"] = df[\"Cust_Id\"].astype(str)\n",
    "    temp_df[\"Movie_Id\"] = df[\"Movie_Id\"].astype(int)\n",
    "    ed = [tuple(row) for _,row in temp_df.iterrows()]\n",
    "    return ed\n",
    "\n",
    "def df_to_nodes(df):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(pd.unique(df[\"Cust_Id\"]).astype(str), bipartite=0)\n",
    "    G.add_nodes_from(pd.unique(df[\"Movie_Id\"]), bipartite=1)\n",
    "    return G\n",
    "\n",
    "def proj(B, nodes):\n",
    "    pred = B.adj\n",
    "    G = nx.Graph()\n",
    "    G.graph.update(B.graph)\n",
    "    G.add_nodes_from((n, B.nodes[n]) for n in nodes)\n",
    "\n",
    "    n_top = float(len(B) - len(nodes))\n",
    "\n",
    "    for u in nodes:\n",
    "        unbrs = set(B[u])\n",
    "        nbrs2 = {n for nbr in unbrs for n in B[nbr]} - {u}\n",
    "        for v in nbrs2:\n",
    "            vnbrs = set(pred[v])\n",
    "            common = unbrs & vnbrs\n",
    "            total_dis = 0\n",
    "            for co in common:\n",
    "                total_dis += abs(B.edges[u, co][\"weight\"] - B.edges[v, co][\"weight\"]) + 1\n",
    "            weight = total_dis/len(common)\n",
    "            G.add_edge(u, v, weight=len(common), dist=weight)\n",
    "    return G\n",
    "\n",
    "def projection(B):\n",
    "    top_nodes = {n for n, d in B.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "    bottom_nodes = set(B) - top_nodes\n",
    "    new_B = proj(B, bottom_nodes)\n",
    "    return new_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(group_dic, index, time_length='year'):\n",
    "    '''\n",
    "    params:\n",
    "        dict: group_dic. This is a dictionary which contains all top 1M data grouped by years\n",
    "        \n",
    "        int: index. It is the index for the saving of image.\n",
    "        \n",
    "        string: time_length. It is the time_length for the group. Default 'year'\n",
    "        \n",
    "    \n",
    "    returns:\n",
    "        networkx_object: B. This is a network with 2 edge properties, distance and weight.\n",
    "        \n",
    "    \n",
    "    This function does four things:\n",
    "        1. Draw and save a graph of the bipartite network for users and movies\n",
    "        2. Draw and save a graph of the projected network for the movies\n",
    "        3. Draw and save a graph of the heat map for the weights of the projected movies.\n",
    "        4. return the projected movie B.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if index >= len(group_dic):\n",
    "        print(\"index out of range\")\n",
    "        return False\n",
    "    ddf = group_dic[index]\n",
    "    GG = df_to_nodes(ddf)\n",
    "    GG.add_weighted_edges_from(df_to_edges(ddf))\n",
    "\n",
    "    \n",
    "    #Get the bipartite graphs.\n",
    "    top_nodes = {n for n, d in GG.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "    bottom_nodes = set(GG) - top_nodes\n",
    "    pos = nx.bipartite_layout(GG, top_nodes)\n",
    "    plt.figure()\n",
    "    \n",
    "    nx.draw_networkx_nodes(GG, nodelist=top_nodes, pos=pos, node_shape=\"d\", node_size=5, linewidths=0.05)\n",
    "    nx.draw_networkx_nodes(GG, nodelist=bottom_nodes, pos=pos, node_shape=\"o\", node_size=5, linewidths=0.05)\n",
    "    nx.draw_networkx_edges(GG, pos=pos, width=0.1)\n",
    "    statement = \"plot/bi/bipartite graph \" + time_length + \" for the \" + str(index) + \" group.png\"\n",
    "    plt.savefig(statement, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    #define a new projection to get the dist and weight\n",
    "    B = projection(GG)\n",
    "    edges_list = list(B.edges(data=True))\n",
    "    #print(edges_list)\n",
    "    #draw the projection graphs\n",
    "    pos = nx.random_layout(B)\n",
    "    #weights = [B[u][v]['weight']/5 for u,v in B.edges]\n",
    "    plt.figure()\n",
    "    nx.draw(B, pos=pos, width=0.01)\n",
    "    statement = \"plot/pro/projected graph \" +  time_length + \" for the \" + str(index) + \" group.png\"\n",
    "    plt.savefig(statement, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    #Get new df\n",
    "    df_new = pd.DataFrame(data=0, columns=df[\"Movie_Id\"].unique(), index=df[\"Movie_Id\"].unique())\n",
    "\n",
    "    #Draw the heat map of the new df\n",
    "    for edge in edges_list:\n",
    "        df_new[edge[0]][edge[1]] = edge[2][\"weight\"]\n",
    "        df_new[edge[1]][edge[0]] = edge[2][\"weight\"]\n",
    "\n",
    "    plt.figure()\n",
    "    fig = sns.heatmap(data=df_new,square=True, cmap=\"RdBu_r\", vmin=0, vmax=20000)\n",
    "    heat_fig = fig.get_figure()\n",
    "    statement = \"plot/heat/heat map of the degrees \" +  time_length + \" for the \" + str(index) + \" group.png\"\n",
    "    heat_fig.savefig(statement, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8351f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027d266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
